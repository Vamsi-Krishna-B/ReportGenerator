{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ab5333",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# llm = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
    "# llm.invoke(\"Hello, world!\",reasoning_format=\"hidden\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,List ,Optional\n",
    "import operator \n",
    "from typing_extensions import Literal,TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage,SystemMessage \n",
    "from IPython.display import display,Image,Markdown\n",
    "from langgraph.types import Send \n",
    "from tavily import TavilyClient\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308ffd1c",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31270f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_from_json(json_data):\n",
    "    json_str = re.search(r\"```json\\n(.*?)\\n```\", json_data.content, re.DOTALL).group(1)\n",
    "    data = json.loads(json_str)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295e1fb",
   "metadata": {},
   "source": [
    "### TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc31d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods = \"Transfer learning ,finetuning of cnn, support vector machine, random forest classifier,linear dicriminant analysis,prinicpal compnent analysis,independent component analysis,genetic alforithm,binary bat optimisation,binary particle swarm optimisation \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods_list = methods.split(',')\n",
    "# methods_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d929927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WikiSearchContent(query):\n",
    "    api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=1000)\n",
    "    wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "    result = wiki.run(query)\n",
    "    llm = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "    prompt = [\n",
    "    SystemMessage(\n",
    "        content=f\"\"\"You are good content writer and also a researcher.\n",
    "        Follow the below instructions while generatin response for the topic: {query}\n",
    "         **Instructions:**\n",
    "        - Each method should include:\n",
    "            - A Title heading (Bold)\n",
    "            • A detailed summary (~500 words)\n",
    "            • Relevant equations\n",
    "            • A separator (e.g., \"---\") at the end\n",
    "        \\n\\n\n",
    "        if found relevant use the below extra content\n",
    "        \\n\\n\n",
    "        {result}\n",
    "        \n",
    "        Note: Dont include any Subheadings!!!! just the content as paragraph is needed.\"\"\"\n",
    "    )\n",
    "]\n",
    "    res = llm.invoke(prompt,reasoning_format=\"hidden\")\n",
    "    return res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44724102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=3,doc_content_chars_max=2500)\n",
    "# wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "# wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c62727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TavilySearchContent(query,top_k):\n",
    "    client = TavilyClient()\n",
    "# Search scientific research articles\n",
    "    results = client.search(\n",
    "    query = query,\n",
    "    include_domains=[\n",
    "        \"google.com\"\n",
    "        \"nature.com\",\n",
    "        \"sciencedirect.com\",\n",
    "        \"springer.com\",\n",
    "        \"ieee.org\",\n",
    "        \"mdpi.com\",\n",
    "        \"researchgate.net\",\n",
    "        \"pubmed.ncbi.nlm.nih.gov\",\n",
    "        \"jamanetwork.com\",\n",
    "        \"frontiersin.org\",\n",
    "        \"hindawi.com\",\n",
    "    ],\n",
    "    search_depth=\"advanced\",       # Enables more comprehensive and scholarly search\n",
    "    max_results=top_k,                # Limit to 15 high-quality results\n",
    "    time_range=\"year\",             # Focus on publications from the past year\n",
    "    include_answer=True,           # Return a concise summary/answer if available\n",
    "    include_images=False,          # Skip irrelevant images\n",
    "    include_raw_content=True    # Include raw text for further processing or embedding\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "    extra_info = []\n",
    "    for result in results['results']:\n",
    "        extra_info.append(result['content']+\" with a score of \"+str(result['score']))\n",
    "    extra_info = \"\\n\\n\".join(extra_info)\n",
    "    return extra_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Initialize the Tavily client (make sure your API key is set in environment variables or config)\n",
    "# client = TavilyClient()\n",
    "# # Search scientific research articles\n",
    "# results = client.search(\n",
    "#     query=\" research paper title with author on independent component analysis\",\n",
    "#     include_domains=[\n",
    "#         \"google.com\"\n",
    "#         \"nature.com\",\n",
    "#         \"sciencedirect.com\",\n",
    "#         \"springer.com\",\n",
    "#         \"ieee.org\",\n",
    "#         \"mdpi.com\",\n",
    "#         \"researchgate.net\",\n",
    "#         \"pubmed.ncbi.nlm.nih.gov\",\n",
    "#         \"jamanetwork.com\",\n",
    "#         \"frontiersin.org\",\n",
    "#         \"hindawi.com\",\n",
    "#     ],\n",
    "#     search_depth=\"advanced\",       # Enables more comprehensive and scholarly search\n",
    "#     max_results=1,                # Limit to 15 high-quality results\n",
    "#     time_range=\"year\",             # Focus on publications from the past year\n",
    "#     include_answer=True,           # Return a concise summary/answer if available\n",
    "#     include_images=False,          # Skip irrelevant images\n",
    "#     include_raw_content=True  # Include raw text for further processing or embedding\n",
    "# )\n",
    "\n",
    "# # Print the results\n",
    "# extra_info = []\n",
    "# for result in results['results']:\n",
    "#     extra_info.append(result['content']+\" with a score of \"+str(result['score']))\n",
    "# extra_info = \"\\n\\n\".join(extra_info)\n",
    "# Markdown(extra_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94384c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "# arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "# arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefcc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown(arxiv.run(\"Transfer Learning\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c4576",
   "metadata": {},
   "source": [
    "### State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac071cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(BaseModel):\n",
    "    title:str=Field(description=\"Title of the section\")\n",
    "    description:str = Field(description=\"Description about the section based on the title given\")\n",
    "    \n",
    "class Sections(BaseModel):\n",
    "    sections:List[Section] = Field(description=\"A list of sections in the report\")\n",
    "     \n",
    "auto_planner = llm.with_structured_output(Sections)\n",
    "\n",
    "class UserInput(TypedDict):\n",
    "    title:str \n",
    "    about_problem:str \n",
    "    methods_used:str\n",
    "    proposed_workflow:str \n",
    "    results:str\n",
    "\n",
    "class AutoState(TypedDict):\n",
    "    topic: str\n",
    "    sections: list[Section] # default empty list   # default empty list\n",
    "    final_report: str \n",
    "    \n",
    "class UserState(TypedDict):\n",
    "    user_input:UserInput\n",
    "    abstract:str\n",
    "    intro:str \n",
    "    methodology:str \n",
    "    proposed_method:str \n",
    "    results:str\n",
    "    references:str \n",
    "    conclusion:str\n",
    "     \n",
    "class State(TypedDict):\n",
    "    user: UserState \n",
    "    auto: AutoState  \n",
    "    is_userInput:Literal[True,False]\n",
    "    completed_sections:Annotated[list,operator.add]\n",
    "    \n",
    "class WorkerState(TypedDict):\n",
    "    section:Section\n",
    "    completed_sections:Annotated[list,operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5055af",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c94db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(state:State):\n",
    "    \"\"\"\n",
    "    Routes the graph flow based on the decision taken by the user.\n",
    "    \"\"\"\n",
    "    print(\"------------ROUTING-------------\")\n",
    "    if state['is_userInput']:\n",
    "        return \"User\"\n",
    "    else:\n",
    "        return \"Auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_abstract(state:State):\n",
    "    \"\"\"\n",
    "    Generates the abstract for the report based on the user input.\n",
    "    \"\"\"\n",
    "    print(\"------------ABSRACT-------------\")\n",
    "    prompt = [\n",
    "        SystemMessage(\n",
    "            content=f\"\"\"\n",
    "                        You are a good researcher and can make standard reports according to the IEEE format. \n",
    "                        You are tasked to make an abstract for the report following the IEEE format based on the below content.\n",
    "                        Also use your own knowledge about neatly presenting the abstract\n",
    "                        Title : {state['user']['user_input']['title']}\n",
    "                        Problem Statement: {state['user']['user_input']['about_problem']}\n",
    "                        Proposed Workflow : {state['user']['user_input']['proposed_workflow']}\n",
    "                        Results : {state['user']['user_input']['results']}\n",
    "                        ---------\n",
    "                        \"\"\"\n",
    "        )\n",
    "    ]\n",
    "    abstract = llm.invoke(prompt,reasoning_format=\"hidden\")\n",
    "    user_data = state.get(\"user\", {})\n",
    "    user_data[\"abstract\"] = abstract.content\n",
    "    # print(abstract.content)\n",
    "    return {\"user\":user_data}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51faaf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_abstract = [\n",
    "#         SystemMessage(\n",
    "#             content=f\"\"\"\n",
    "#                         You are a good researcher and can make standard reports according to the IEEE format. \n",
    "#                         You are tasked to make an abstract for the report following the IEEE format based on the below content.\n",
    "#                         Also use your own knwowledge about neatly presenting the abstract\n",
    "#                         \\n\\n\n",
    "#                         Title : Fusion of Texture and Deep Feature for Laryngeal Cancer Detection \n",
    "#                         \\n\\n\n",
    "#                         Problem Statement: Laryngeal cancer is a major global health concern, with increasing incidence \n",
    "#                         primarily associated with risk factors such as tobacco use, excessive alcohol\n",
    "#                         consumption, and viral infections.Using of Laryngeal cancer tissue patch images.\n",
    "#                          \\n\\n\n",
    "#                         Proposed Workflow : This study introduces a high-performance Deep Convolutional Neural Network (CNN)-based system\n",
    "#                         using ResNet152V2, enhanced with Segmentation-Based Fractal Texture Analysis (SFTA) for \n",
    "#                         feature extraction and Linear Discriminant Analysis (LDA) for dimensionality reduction. \n",
    "#                         Classification is performed using Kernel Support Vector Machine (SVM), ensuring higher precision in detecting laryngeal cancer.\n",
    "#                         . To evaluate the proposed framework, we implement five types of K-fold cross-validation(K = 2, 3, 4, 5, and 10).  \n",
    "#                         \\n\\n\n",
    "#                         Results :  achieving a mean training accuracy of 99.92%, mean testing accuracy of 99.92%, and\n",
    "#                         mean precision, recall, and F1-scores of 99.92% under the K=10 cross-validation protocol.                                                \n",
    "#                         \"\"\"   \n",
    "#         )\n",
    "#     ]\n",
    "# abstract = llm.invoke(prompt_abstract,reasoning_format=\"hidden\")\n",
    "# abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_introduction(state: State):\n",
    "    \"\"\"\n",
    "    Generates the Introduction for the report based on the user input.\n",
    "    \"\"\"\n",
    "    print(\"------------INTRODUCTION------------\")\n",
    "    extra_info = TavilySearchContent(state['user']['user_input']['about_problem'],top_k=15)\n",
    "    prompt = [\n",
    "        SystemMessage(\n",
    "            content=f\"\"\"\n",
    "                        You are a good researcher and can make standard reports according to the IEEE format. \n",
    "                        You are tasked to draft an Introduction for the report following the IEEE format based on the below content.\n",
    "                        \n",
    "                        Problem Statement:{state['user']['user_input']['about_problem']}\n",
    "                        ----------------------------------------------------------------\n",
    "                          \\n\\n\n",
    "                        Also try to include the whole below given extra information in framing the introduction like stating about the problem and then \n",
    "                        include all of the data from extra information to give a story type large introduction discussing about all\n",
    "                        of the methodologies used.\n",
    "                        and finally add the proposed workflow and highlight how the current proposed method would be better and can improve results\n",
    "                        Extra Information:\n",
    "                        \\n\\n\n",
    "                        {extra_info} \n",
    "                        \\n\\n\n",
    "                        --------------------------------------------------------------------\n",
    "                         Proposed Workflow : {state['user']['user_input']['proposed_workflow']}\n",
    "                         \n",
    "                         **DONOT MENTION ABOUT THE REFERENCES HERE**\n",
    "                        \"\"\"\n",
    "        )\n",
    "    ]\n",
    "    introduction = llm.invoke(prompt, reasoning_format=\"hidden\")\n",
    "    user_data = state.get(\"user\", {})\n",
    "    # print(introduction.content)\n",
    "    user_data[\"introduction\"] = introduction.content\n",
    "    return {\"user\":user_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = [\n",
    "#         SystemMessage(\n",
    "#             content=f\"\"\"\n",
    "#                         You are a good researcher and can make standard reports according to the IEEE format. \n",
    "#                         You are tasked to draft an Introduction for the report following the IEEE format based on the below content.\n",
    "                        \n",
    "#                         Problem Statement: Laryngeal cancer is a major global health concern, with increasing incidence \n",
    "#                          primarily associated with risk factors such as tobacco use, excessive alcohol\n",
    "#                          consumption, and viral infections.Using of Laryngeal cancer tissue patch images.\n",
    "#                           \\n\\n\n",
    "#                         Also try to include the whole below given extra information in framing the introduction like stating about the problem and then \n",
    "#                         include all of the data from extra information to give a story type large introduction discussing about all\n",
    "#                         of the methodologies used.\n",
    "#                         and finally add the proposed workflow and highlight how the current proposed method would be better and can improve results\n",
    "#                         Extra Information:\n",
    "#                         \\n\\n\n",
    "#                         {extra_info} \n",
    "#                         \\n\\n\n",
    "                        \n",
    "#                          Proposed Workflow : This study introduces a high-performance Deep Convolutional Neural Network (CNN)-based system\n",
    "#                          using ResNet152V2, enhanced with Segmentation-Based Fractal Texture Analysis (SFTA) for \n",
    "#                          feature extraction and Linear Discriminant Analysis (LDA) for dimensionality reduction. \n",
    "#                          Classification is performed using Kernel Support Vector Machine (SVM), ensuring higher precision in detecting laryngeal cancer.\n",
    "#                          . To evaluate the proposed framework, we implement five types of K-fold cross-validation(K = 2, 3, 4, 5, and 10).\n",
    "#                         ---------\n",
    "#                         Returns : \n",
    "#                         (dict)\n",
    "                        \n",
    "#                         dict contains keys: \n",
    "#                         title and description\n",
    "#                         title as introduction\n",
    "#                         description as the content which need to be filled.\n",
    "#                         \"\"\"\n",
    "#         )\n",
    "#     ]\n",
    "# introduction = user_planner.invoke(prompt,reasoning_format=\"hidden\")\n",
    "# Markdown(introduction.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c78374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_methodology(state:State):\n",
    "    \"\"\"\n",
    "     Generates the Methodology Section of the report explaining and highlighting about the methodologies used in the proposed work.\n",
    "    \"\"\"\n",
    "    print(\"------------METHODOLOGY-------------\")\n",
    "    methods = state['user']['user_input']['methods_used']\n",
    "    methods = methods.split(\",\")\n",
    "    methodology = ' **Methodology** \\n'\n",
    "    for method in methods:\n",
    "        methodology+= WikiSearchContent(method)\n",
    "    # print(methodology)\n",
    "    user_data = state.get(\"user\", {})\n",
    "    user_data[\"methodology\"] = methodology\n",
    "    return {\"user\":user_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods = \"\"\"Transfer learning ,finetuning of cnn,\n",
    "# support vector machine, random forest classifier,\n",
    "# linear dicriminant analysis,\n",
    "# prinicpal compnent analysis,\n",
    "# independent component analysis,\n",
    "# genetic alforithm,binary bat optimisation,\n",
    "# binary particle swarm optimisation \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479eb555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods = methods.split(\",\")\n",
    "# methodology = \"\"\" \"\"\"\n",
    "# for method in methods:\n",
    "#     methodology+= WikiSearchContent(method)\n",
    "# Markdown(methodology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b75550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_proposed = \"\"\"\n",
    "# Deep CNN - based model that uses:\n",
    "\n",
    "# ResNet152V2 + SFTA for fusion feature extraction,\n",
    "\n",
    "# Linear Discriminant Analysis (LDA) for dimensionality reduction, and\n",
    "\n",
    "# Kernel SVM for classification.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82771a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = [\n",
    "#         SystemMessage(\n",
    "#             content=f\"\"\"\n",
    "#                 You are a good researcher and can make standard reports according to the IEEE format. \n",
    "#                You are tasked to draft an Proposed Method for the report following the IEEE format based on the below content.\n",
    "#                 You can understand the below given method workflow and explain and Enhance more about the method\n",
    "#                 \\n \n",
    "#                 {user_proposed}\n",
    "#                 Returns : \n",
    "#                         (dict)\n",
    "                        \n",
    "#                         dict contains keys: \n",
    "#                         title and description\n",
    "#                         title as Proposed Method\n",
    "#                         description as the content which need to be filled.\n",
    "#             \"\"\"\n",
    "#         )\n",
    "#     ]\n",
    "# result = user_planner.invoke(prompt,reasoning_format=\"hidden\")\n",
    "# Markdown(result.description)\n",
    "#     # return {\"user\":{\"proposed_method\":result.content}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e820f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_proposed_method(state:State):\n",
    "    \"\"\"\n",
    "    Generates the proposed method Section of the report explaining how the workflow is.\n",
    "    \"\"\"\n",
    "    print(\"------------PORPOSED METHOD-------------\")\n",
    "    user_proposed = state['user']['user_input']['proposed_workflow']\n",
    "    prompt = [\n",
    "        SystemMessage(\n",
    "            content=f\"\"\"\n",
    "                You are a good researcher and can make standard reports according to the IEEE format. \n",
    "               You are tasked to draft an Proposed Method for the report following the IEEE format based on the below content.\n",
    "                You can understand the below given method workflow and explain and Enhance more about the method\n",
    "                \\n \n",
    "                {user_proposed}\n",
    "                ** DONOT ADD REFERENCES HERE **\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "    result = llm.invoke(prompt,reasoning_format=\"hidden\")\n",
    "    user_data = state.get(\"user\", {})\n",
    "    user_data[\"proposed_method\"] = result.content\n",
    "    # print(result.content)\n",
    "    return {\"user\":user_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(state:State):\n",
    "    \"\"\"\n",
    "    Generates the result section of the report explaining\n",
    "    \"\"\"\n",
    "    print(\"------------RESULTS-------------\")\n",
    "    user_results = state['user']['user_input']['results']\n",
    "    prompt = [\n",
    "        SystemMessage(\n",
    "            content=f\"\"\"\n",
    "                You are a good researcher and can make standard reports according to the IEEE format. \n",
    "               You are tasked to draft an  Result for the report following the IEEE format based on the below content.\n",
    "                Frame the results in well mannered format.\n",
    "                \\n \n",
    "                {user_results}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "    result = llm.invoke(prompt,reasoning_format=\"hidden\")\n",
    "    user_data = state.get(\"user\", {})\n",
    "    user_data[\"results\"] = result.content\n",
    "    # print(result.content)\n",
    "    return {\"user\":user_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630afecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conclusion(state:State):\n",
    "    \"\"\"\n",
    "    Generates the conclusion section of the report\n",
    "    \"\"\"\n",
    "    print(\"------------CONCLUSION-------------\")\n",
    "    prompt = [\n",
    "        SystemMessage(\n",
    "            content=f\"\"\"\n",
    "            You are a good researcher and can make standard reports according to the IEEE format. \n",
    "               You are tasked to draft the conclusion section for the report following the IEEE format based on the below content.\n",
    "               Elaborate and Include how in future new methods can be added to this work.\n",
    "               \\n\\n\n",
    "               {state['user']['abstract']}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "    result = llm.invoke(prompt,reasoning_format=\"hidden\")\n",
    "    user_data = state.get(\"user\", {})\n",
    "    user_data[\"conclusion\"] = result.content\n",
    "    # print(result.content)\n",
    "    return {\"user\":user_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_references(state:State):\n",
    "    \"\"\"\n",
    "    Generates the References section of the report.\n",
    "    \"\"\"\n",
    "    print(\"------------REFERENCES-------------\")\n",
    "    methods = state['user']['user_input']['methods_used']\n",
    "    prompt = [\n",
    "        SystemMessage(\n",
    "            content=f\"\"\"\n",
    "            You are a good researcher and can make standard reports according to the IEEE format. \n",
    "               You are tasked to draft an  References for the report following the IEEE format based on the below content.\n",
    "               Extract the two refernce per method information as per IEEE format from below methods.\n",
    "               {methods}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "    result = llm.invoke(prompt,reasoning_format=\"hidden\")\n",
    "    user_data = state.get(\"user\", {})\n",
    "    user_data[\"references\"] = result.content\n",
    "    # print(result.content)\n",
    "    return {\"user\":user_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6716b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = [\n",
    "#         SystemMessage(\n",
    "#             content=f\"\"\"\n",
    "#             You are a good researcher and can make standard reports according to the IEEE format. \n",
    "#                You are tasked to draft the conclusion section for the report following the IEEE format based on the below content.\n",
    "#                Elaborate and Include how in future new methods can be added to this work.\n",
    "#                \\n\\n\n",
    "#                This study presents an advanced laryngeal cancer detection system that integrates deep learning with texture analysis. The proposed framework combines ResNet152V2 for deep feature extraction with Segmentation-Based Fractal Texture Analysis (SFTA) to capture microstructural patterns. Dimensionality reduction using Linear Discriminant Analysis (LDA) enhances feature discrimination, followed by Kernel Support Vector Machine (SVM) classification. Evaluated through 10-fold cross-validation, the system achieves a mean testing accuracy of 99.92% with precision, recall, and F1-scores of 99.92%, demonstrating its robustness for clinical application in early laryngeal cancer diagnosis.\n",
    "#                 Returns : \n",
    "#                         (dict)\n",
    "                        \n",
    "#                         dict contains keys: \n",
    "#                         title and description\n",
    "#                         title as Conclusion\n",
    "#                         description as the content which need to be filled.\n",
    "#             \"\"\"\n",
    "#         )\n",
    "#     ]\n",
    "# result = user_planner.invoke(prompt,reasoning_format=\"hidden\")\n",
    "# Markdown(result.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_report(state:State):\n",
    "    \"\"\"\n",
    "    Combines the all generated section's content\n",
    "    \"\"\"\n",
    "    combined_sections = \"\\n\\n\".join(\n",
    "    str(value) for key, value in state['user'].items() if key != \"user_input\"\n",
    ")   \n",
    "    user_data = state.get(\"user\", {})\n",
    "    user_data[\"final_report\"] = combined_sections\n",
    "    # print(result.content)\n",
    "    return {\"user\":user_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ba444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orcehstrator(state:State):\n",
    "    \"\"\" Orchestrtor that generates plan for the report\"\"\"\n",
    "    print(\"In orchestrator\")\n",
    "    report_sections = auto_planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"You are a world class research assistant,and you are great at creating outlines for reports\"),\n",
    "            HumanMessage(content=f\"Create a detailed outline for a report on the topic:{state['auto']['topic']}.List at least 5 sections with name and description\"),\n",
    "        ],reasoning_format=\"hidden\"\n",
    "    )\n",
    "    print(\"In orchestrator after llm\")\n",
    "    # print(\"Report Sections:\",report_sections)\n",
    "\n",
    "    return {\"auto\":{\"sections\":report_sections.sections}}\n",
    "\n",
    "\n",
    "def llm_call(state:State):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                        content=f\"Write a report section following the provided name and description. Include no preamble for each section.Used markdown formatting\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"here is the section name : {state['auto']['section'].title} and description: {state['auto']['section'].description}\"\n",
    "            )\n",
    "        ],reasoning_format=\"hidden\"\n",
    "    )\n",
    "    return {\"completed_sections\":[section.content]}\n",
    "\n",
    "\n",
    "def assign_workers(state:State):\n",
    "    \"\"\"Assign workers to each section of the report\"\"\"\n",
    "    return [Send(\"llm_call\",{\"auto\":{\"section\":s}}) for s in state['auto']['sections']]\n",
    "\n",
    "def synthesizer(state:State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "    print(state['auto'].keys())\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "    \n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "    return {\"auto\":{\"final_report\":completed_report_sections}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7722a48",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END \n",
    "\n",
    "builder = StateGraph(State)\n",
    "# builder.add_node(\"router\",route)\n",
    "builder.add_node(\"abstract\",generate_abstract)\n",
    "builder.add_node(\"introduction\",generate_introduction)\n",
    "builder.add_node(\"methodology\",generate_methodology)\n",
    "builder.add_node(\"proposed\",generate_proposed_method)\n",
    "builder.add_node(\"results\",generate_results)\n",
    "builder.add_node(\"references\",generate_references)\n",
    "builder.add_node(\"conclusion\",generate_conclusion)\n",
    "builder.add_node(\"final_report\",final_report)\n",
    "builder.add_node(\"orchestrator\",orcehstrator)\n",
    "builder.add_node(\"llm_call\",llm_call)\n",
    "builder.add_node(\"synthesizer\",synthesizer)\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    START,\n",
    "    route,\n",
    "    {\n",
    "        \"User\":\"abstract\",\n",
    "        \"Auto\":\"orchestrator\"\n",
    "    },\n",
    ")\n",
    "builder.add_edge(\"abstract\",\"introduction\")\n",
    "builder.add_edge(\"introduction\",\"methodology\")\n",
    "builder.add_edge(\"methodology\",\"proposed\")\n",
    "builder.add_edge(\"proposed\",\"results\")\n",
    "builder.add_edge(\"results\",\"conclusion\")\n",
    "builder.add_edge(\"conclusion\",\"references\")\n",
    "builder.add_edge(\"references\",\"final_report\")\n",
    "builder.add_edge(\"final_report\",END)\n",
    "builder.add_conditional_edges(\n",
    "    \"orchestrator\",\n",
    "    assign_workers,\n",
    "    [\"llm_call\"],\n",
    ")\n",
    "builder.add_edge(\"llm_call\",\"synthesizer\")\n",
    "builder.add_edge(\"synthesizer\",END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = graph.invoke({\n",
    "    \"is_userInput\": False,\n",
    "    \"auto\": {\n",
    "        \"topic\": \"An detailed report on the impact of use of Agentic AI applications in software development\",\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = graph.invoke(\n",
    "#     {\n",
    "#         \"is_userInput\": True,\n",
    "#         \"user\": {\n",
    "#            \"user_input\": {\n",
    "#         \"title\": \"Laryngeal Cancer Detection Using Deep CNN and Feature Fusion\",\n",
    "#         \"about_problem\": \"Recent researches done on Laryngeal Cancer detection\",\n",
    "        \n",
    "#         \"methods_used\": \"ResNet152V2 CNN, SFTA texture analysis, feature fusion, Linear Discriminant Analysis, Kernel SVM, K-fold cross-validation.\",\n",
    "        \n",
    "#         \"proposed_workflow\": \"Collect and preprocess laryngeal images. Extract deep features with ResNet152V2 and texture features with SFTA. Fuse features, reduce dimensionality with LDA, and classify using Kernel SVM. Evaluate with K-fold cross-validation.\",\n",
    "        \n",
    "#         \"results\": \"The model achieved 99.89% training and 99.85% testing accuracy, demonstrating strong generalization and robustness for automated laryngeal cancer detection.\"\n",
    "#     }\n",
    "#         },\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9190de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown(report['auto']['final_report'])\n",
    "Markdown(report['auto']['final_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown(report['user']['final_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b002cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = report[\"auto\"][\"final_report\"]  # or whatever large text you have\n",
    "\n",
    "html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>Plant Leaf Disease Detection Report</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: Arial, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            margin: 40px;\n",
    "        # }}\n",
    "        h1, h2, h3 {{\n",
    "            color: #2E8B57;\n",
    "        }}\n",
    "        pre {{\n",
    "            white-space: pre-wrap;\n",
    "            word-wrap: break-word;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Automated Plant Leaf Disease Detection Using Deep Learning</h1>\n",
    "    <pre>{content}</pre>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Save to HTML file\n",
    "with open(\"plant_leaf_report.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(\"✅ HTML file saved as plant_leaf_report.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReportGenerator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
